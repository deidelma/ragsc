{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion\n",
    "\n",
    "Attempt to apply the approach used by [Nir Diamant](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval.ipynb) to the ragsc problem.\n",
    "\n",
    "## Strategy\n",
    "\n",
    "Consider each cluster as a \"document\".  Using a random sample of the cluster data and associated embeddings, create a vector database\n",
    "using FAISS or Chroma.  At the same time, use Lucene to create an index for the \"documents\".  Score matches on both semantic (vector) and keyword (BM25) and combine the scores to see if we can get more success matching to clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# import libraries\n",
    "#\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from functools import partial, reduce\n",
    "from typing import Union\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# set constants\n",
    "#\n",
    "input_path = Path(\"../results\")\n",
    "output_path = Path(\"../results\")\n",
    "training_fraction = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 9370\n",
      "training set has 4685 rows\n",
      "test set has 4685 rows\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# load the data along with embeddings\n",
    "#\n",
    "master_df = pd.read_csv(input_path / Path(\"ragsc_00_all_large.csv\"))\n",
    "master_n_cells = master_df.shape[0]\n",
    "\n",
    "train_df = master_df.sample(frac=training_fraction)\n",
    "test_df= master_df.drop(train_df.index) #.sample(frac=training_fraction) \n",
    "print(f\"total rows: {master_df.shape[0]}\")\n",
    "print(f\"training set has {train_df.shape[0]} rows\")\n",
    "print(f\"test set has {test_df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 586\n",
      "1 548\n",
      "2 377\n",
      "3 375\n",
      "4 354\n",
      "5 317\n",
      "6 287\n",
      "7 275\n",
      "8 242\n",
      "9 200\n",
      "10 200\n",
      "11 184\n",
      "12 169\n",
      "13 155\n",
      "14 108\n",
      "15 99\n",
      "16 104\n",
      "17 62\n",
      "18 43\n"
     ]
    }
   ],
   "source": [
    "for cluster in test_df.groupby('cluster'):\n",
    "    print(cluster[0], cluster[1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_bags(df: pd.DataFrame, max_genes:int, sort_by_cluster_names=True) -> dict:\n",
    "    \"\"\"\n",
    "    Produces \"bags of words\" for each cluster to use as documents in BM25 analysis.\n",
    "    \n",
    "    Returns a dictionary with cluster name as the keys and a list of gene names as the values.\n",
    "    \"\"\"\n",
    "    clusters = df.groupby(\"cluster\", sort=False)\n",
    "    word_dict = {}\n",
    "    for cluster in clusters:\n",
    "        # each cluster is a tuple (cluster name, cluster dataframe)\n",
    "        words = []\n",
    "        cluster_df = cluster[1] # the dataframe\n",
    "        # convert each signature into a list of string\n",
    "        word_series = cluster_df.signature.apply(lambda x: x.split(\" \"))\n",
    "        # create a bag of words based containing the gene names for this cluster\n",
    "        for sig in word_series:\n",
    "            # retain only max_genes gene names to add to the bag of words\n",
    "            words.extend(sig[:max_genes]) \n",
    "        word_dict[cluster[0]] = words\n",
    "    if sort_by_cluster_names:\n",
    "        word_dict = {k: word_dict[k] for k in sorted(word_dict)}\n",
    "    return word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# chunking\n",
    "#\n",
    "def chunk(s:Union[str,list], size:int, step=1) -> list[str]:\n",
    "    \"\"\"\n",
    "    Takes a string or list of strings and creates a list of overlapping chunks of a given size.\n",
    "\n",
    "    Args\n",
    "        size: The number of words (gene names) in each chunk.\n",
    "        step: The number of words to advance before the next chunk (defaults to 1).\n",
    "    Returns\n",
    "        A list of strings representing the chunks.\n",
    "    \"\"\"\n",
    "    if isinstance(s,str):\n",
    "        a = s.split()\n",
    "    else:\n",
    "        a = s\n",
    "    results = []\n",
    "    max = len(a)\n",
    "    for i in range(max):\n",
    "        if i+size < max:\n",
    "            results.append(\" \".join(a[i:i+size]))\n",
    "        else:\n",
    "            results.append(\" \".join(a[i:]))\n",
    "        i += step\n",
    "    return results\n",
    "    \n",
    "# chunks = chunk(\"this is a test of the splitter\", 3)\n",
    "# print(chunks)\n",
    "chunk2 = partial(chunk, size=2,step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = get_gene_bags(train_df,max_genes=120)\n",
    "\n",
    "#\n",
    "# create index from the cluster \"documents\" which are stored in word_dict\n",
    "#\n",
    "docs = [chunk2(\" \".join(x)) for x in word_dict.values()]\n",
    "bm25_index = BM25Okapi(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(bm25, gene_list, max_genes=25, normalized=True) -> list[float]:\n",
    "    \"\"\"\n",
    "    Returns a list containing the scores for a particular list of genes\n",
    "    \"\"\"\n",
    "    query = chunk2(gene_list)[:max_genes]\n",
    "    scores = bm25.get_scores(query)\n",
    "    if normalized:\n",
    "        scores = (scores - np.min(scores))/(np.max(scores)-np.min(scores))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_score_column(df:pd.DataFrame, bm25, max_genes) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a column to the provided dataframe containing the BM25 scores.\n",
    "\n",
    "    Args:\n",
    "        df - the dataframe whose signatures will be used to generate the scores\n",
    "        bm25 - the index to use fo comparison\n",
    "        max_genes - the maximum number of genes to include from each signature\n",
    "\n",
    "    Returns a reference to the original dataframe\n",
    "    \"\"\"\n",
    "    df['scores'] = df.signature.apply(lambda x: get_score(bm25, x, max_genes))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = create_score_column(test_df, bm25_index, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.         0.15734795 0.96343006 0.69476747 0.45294369 0.70264113\n",
      " 0.24852422 0.25640868 0.56046134 0.46370086 0.29132395 0.\n",
      " 0.03921402 0.         0.         0.4040511  0.         0.29088538\n",
      " 0.        ] 1.0\n"
     ]
    }
   ],
   "source": [
    "n=121\n",
    "cluster = test_df.cluster.iloc[n]\n",
    "scores = test_df.scores.iloc[n]\n",
    "rating = scores[cluster]\n",
    "print(cluster, scores, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     0.87     0.74\n",
      "    1     0.45     0.71\n",
      "    2     0.37     0.47\n",
      "    3     0.38     0.64\n",
      "    4     0.79     0.00\n",
      "    5     1.00     0.00\n",
      "    6     1.00     0.56\n",
      "    7     0.75     0.00\n",
      "    8     0.52     0.36\n",
      "    9     1.00     0.00\n",
      "   10     0.28     0.00\n",
      "   11     1.00     0.42\n",
      "   12     0.00     0.00\n",
      "   13     0.68     0.00\n",
      "   14     0.00     0.00\n",
      "   15     0.00     0.00\n",
      "   16     0.40     0.64\n",
      "   17     0.00     0.06\n",
      "   18     0.00     0.00\n"
     ]
    }
   ],
   "source": [
    "row = 25\n",
    "clusters = df_test.groupby('cluster')\n",
    "for cluster in clusters:\n",
    "    # print(cluster[1].shape)\n",
    "    local_df = cluster[1]\n",
    "    no = cluster[0]\n",
    "    if no> 0:\n",
    "        bad = no-1\n",
    "    else:\n",
    "        bad = no+1\n",
    "    scores = local_df.scores.iloc[row]\n",
    "    # print(scores)\n",
    "    print(f\"{no:5} {scores[no]:8.2f} {scores[bad]:8.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4685\n",
      "\n",
      "Cluster: 00:    0.855 (586)\n",
      "Cluster: 01:    0.568 (548)\n",
      "Cluster: 02:    0.644 (377)\n",
      "Cluster: 03:    0.756 (375)\n",
      "Cluster: 04:    0.538 (354)\n",
      "Cluster: 05:    0.848 (317)\n",
      "Cluster: 06:    0.711 (287)\n",
      "Cluster: 07:    0.486 (275)\n",
      "Cluster: 08:    0.663 (242)\n",
      "Cluster: 09:    0.774 (200)\n",
      "Cluster: 10:    0.732 (200)\n",
      "Cluster: 11:    0.773 (184)\n",
      "Cluster: 12:    0.296 (169)\n",
      "Cluster: 13:    0.391 (155)\n",
      "Cluster: 14:    0.432 (108)\n",
      "Cluster: 15:    0.482 (99)\n",
      "Cluster: 16:    0.239 (104)\n",
      "Cluster: 17:    0.188 (62)\n",
      "Cluster: 18:    0.156 (43)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# explore the effect of sample size on mean score\n",
    "#\n",
    "print(test_df.shape[0])\n",
    "print()\n",
    "sum=0\n",
    "n_clusters = 19\n",
    "count=0\n",
    "# test_df['scores_sum'] = test_df.scores.apply(lambda x: np.sum(x))\n",
    "for cluster in test_df.groupby('cluster'):\n",
    "    cluster_no = cluster[0]\n",
    "    cluster_df = cluster[1]\n",
    "    cluster_df['predicted_score'] = cluster_df.scores.apply(lambda x: x[cluster_no])\n",
    "    # assume score is normalized\n",
    "    avg_score_for_cluster = cluster_df.predicted_score.sum() / cluster_df.shape[0]\n",
    "    print(f\"Cluster: {cluster_no:02}: {avg_score_for_cluster:8.3f} ({cluster_df.shape[0]:02})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 00:(646)\n",
      "Cluster: 01:(526)\n",
      "Cluster: 02:(414)\n",
      "Cluster: 03:(352)\n",
      "Cluster: 04:(341)\n",
      "Cluster: 05:(298)\n",
      "Cluster: 06:(284)\n",
      "Cluster: 07:(266)\n",
      "Cluster: 08:(249)\n",
      "Cluster: 09:(206)\n",
      "Cluster: 10:(198)\n",
      "Cluster: 11:(184)\n",
      "Cluster: 12:(145)\n",
      "Cluster: 13:(138)\n",
      "Cluster: 14:(112)\n",
      "Cluster: 15:(102)\n",
      "Cluster: 16:(95)\n",
      "Cluster: 17:(86)\n",
      "Cluster: 18:(43)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# explore the effect of training set size on mean score\n",
    "#\n",
    "for cluster in train_df.groupby('cluster'):\n",
    "    cluster_no = cluster[0]\n",
    "    cluster_df = cluster[1]\n",
    "    print(f\"Cluster: {cluster_no:02}:({cluster_df.shape[0]:02})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# save intermediate results\n",
    "#\n",
    "train_df.to_csv(\"data/train.csv\")\n",
    "test_df.to_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector database strategy\n",
    "\n",
    "Each cluster is a text document.\n",
    "Each cell signature is a sentence.\n",
    "Need to chunk the cluster documents and restrict sentences to the highest expression genes. A reasonable cut point is 120 genes based on the BM25 analysis, which showed plateauing in the matches at around this number of \"words\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562200\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# docs contains the chunked gene names by cluster\n",
    "#\n",
    "\n",
    "total = reduce(lambda x,y: x+y, [len(x) for x in docs],0)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# given that current form of docs is prohibitively large (n=562200 chunks),\n",
    "# will use current embeddings as a first attempt\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embeddings(\n",
    "    collection: chromadb.Collection,\n",
    "    df: pd.DataFrame,\n",
    "    min_item=0,\n",
    "    max_item=-1,\n",
    "    embeddings_column: str = \"embeddings\",\n",
    "    docs_column: str = \"cluster\",\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Stores embeddings in the provided ChromaDB collection.\n",
    "\n",
    "    Args\n",
    "    collection: the collection to receive the data\n",
    "    df : the dataframe from which the data is derived\n",
    "    min_item: the minimum row number to use\n",
    "    max_item: the maximum row number to use, defaults to -1 (all rows)\n",
    "    embeddings_column: the column containing the embeddings, defaults to \"embeddings\"\n",
    "    docs_column: the column containing the document name, defaults to \"cluster\"\n",
    "\n",
    "    Rerturns the number of embeddings added to the database\n",
    "    \"\"\"\n",
    "    if max_item == -1:\n",
    "        max_item = df.shape[0]\n",
    "    if max_item <= min_item:\n",
    "        logger.error(\"max_item must be greater than min_item\")\n",
    "        return 0\n",
    "    docs = [] # clusters\n",
    "    embeds = [] # embeddings\n",
    "    ids = [] # cell ids\n",
    "    for i in range(min_item, max_item):\n",
    "        docs.append(str(df[docs_column].iloc[i]))\n",
    "        embeds.append(json.loads(df[embeddings_column].iloc[i]))\n",
    "        ids.append(str(df.index[i]))\n",
    "    try:\n",
    "        collection.add(documents=docs, embeddings=embeds, ids=ids)\n",
    "    except Exception as e:\n",
    "        logger.error(\"unable to load data into database\")\n",
    "        logger.exception(e)\n",
    "        return 0\n",
    "    else:\n",
    "        return max_item - min_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_database(collection_name: str = \"ragsc\") -> chromadb.Collection:\n",
    "    client = chromadb.Client()\n",
    "    try:\n",
    "        c = client.get_collection(collection_name)\n",
    "        client.delete_collection(collection_name)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    c = client.create_collection(collection_name)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_database(df: pd.DataFrame) -> chromadb.Collection:\n",
    "    \"\"\"\n",
    "    creates an in memory ChromaDB collection  based on the data in the \n",
    "    provided dataframe.\n",
    "    \"\"\"\n",
    "    collection = initialize_database()\n",
    "    df = df[~df.signature.isnull()]  # clean any empty signatures\n",
    "    store_embeddings(collection, df)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_embeddings(embeddings:str, collection:chromadb.Collection, n_results=100):\n",
    "    results = collection.query(\n",
    "        query_embeddings=[json.loads(embeddings)],\n",
    "        n_results=n_results,\n",
    "        include=[\"documents\",\"distances\"])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# need to test results based on cluster orientation\n",
    "#\n",
    "def test_item(df: pd.DataFrame, row: int, collection: chromadb.Collection, n_results=100):\n",
    "    # print(f\"Original cluster: {df.cluster.iloc[row]}\")\n",
    "    results = collection.query(\n",
    "        query_embeddings=[json.loads(df.embeddings.iloc[row])],\n",
    "        n_results=n_results,\n",
    "        include=[\"documents\",\"distances\"]\n",
    "    )\n",
    "    # print(results)\n",
    "    # return zip(results['documents'],results['distances'])\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# first attempt\n",
    "#\n",
    "coll = setup_database(train_df)\n",
    "results = test_item(test_df,0,coll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_score(data: list[float], offset = 0.01)->float:\n",
    "    if len(data) == 0:\n",
    "        return 0 \n",
    "    a = np.array(data)\n",
    "    a = np.log10(1.0/(a+offset))\n",
    "    return a.sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_score_per_row(embeddings:str, coll, n_results=100, max_clusters=19):\n",
    "    results = test_embeddings(embeddings,coll)\n",
    "    pairs = list(zip(results['documents'][0],results['distances'][0]))\n",
    "    table ={}\n",
    "    for k in range(max_clusters): \n",
    "        table[k] = []\n",
    "    for item in pairs:\n",
    "        table[int(item[0])].append(item[1])\n",
    "    scores = []\n",
    "    for k in table:\n",
    "        scores.append(distance_score(table[k]))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_distance_score(df: pd.DataFrame, coll: chromadb.Collection, n_results=100) -> None:\n",
    "    \"\"\"\n",
    "    Calculates distance_score on a row-wise basis, storing the results\n",
    "    in column \"d_score\" and normalized (x-min/max-min) in \"n_score\".\n",
    "    \n",
    "    This works in-place, modifying the input dataframe by adding two columns.\n",
    "    \"\"\"\n",
    "    # first create columns of lists to store the results\n",
    "    df['d_score'] = [[] for i in range(df.shape[0])]\n",
    "    df['n_score'] = [[] for i in range(df.shape[0])]\n",
    "\n",
    "    # now calculate the scores and normalized scores\n",
    "    df.d_score = df.embeddings.apply(lambda x: distance_score_per_row(x, coll))\n",
    "    df.n_score = df.d_score.apply(lambda x: (x-np.min(x))/(np.max(x) - np.min(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# calculate the distance scores\n",
    "#\n",
    "apply_distance_score(test_df, coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_no</th>\n",
       "      <th>cluster</th>\n",
       "      <th>signature</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>scores</th>\n",
       "      <th>d_score</th>\n",
       "      <th>n_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RPL11 CEP350 GNLY PTPN4 ZBTB20 SMARCA5 KIAA082...</td>\n",
       "      <td>TGACCAAGTAGACAAA</td>\n",
       "      <td>[0.022202235, 0.0039805206, -0.006030237, 0.01...</td>\n",
       "      <td>[1.0, 0.5899505384390359, 0.7178018238587968, ...</td>\n",
       "      <td>[36.66195147104413, 0.919602741008284, 23.6148...</td>\n",
       "      <td>[1.0, 0.02508330037299277, 0.644125315373835, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>RIPOR2 ATXN1 HIBADH JAZF1 PDE3B ARID1A TUT4 TR...</td>\n",
       "      <td>AATCATCCAGTTTACG</td>\n",
       "      <td>[0.027102128, 0.016445303, -0.009962541, 0.008...</td>\n",
       "      <td>[1.0, 0.7138399779046296, 0.5878873131841577, ...</td>\n",
       "      <td>[3.1389357931347757, 36.37367301229885, 10.385...</td>\n",
       "      <td>[0.0862969156860629, 1.0, 0.2855244271063499, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cell_no  cluster                                          signature  \\\n",
       "0        0        0  RPL11 CEP350 GNLY PTPN4 ZBTB20 SMARCA5 KIAA082...   \n",
       "3        3        0  RIPOR2 ATXN1 HIBADH JAZF1 PDE3B ARID1A TUT4 TR...   \n",
       "\n",
       "            cell_id                                         embeddings  \\\n",
       "0  TGACCAAGTAGACAAA  [0.022202235, 0.0039805206, -0.006030237, 0.01...   \n",
       "3  AATCATCCAGTTTACG  [0.027102128, 0.016445303, -0.009962541, 0.008...   \n",
       "\n",
       "                                              scores  \\\n",
       "0  [1.0, 0.5899505384390359, 0.7178018238587968, ...   \n",
       "3  [1.0, 0.7138399779046296, 0.5878873131841577, ...   \n",
       "\n",
       "                                             d_score  \\\n",
       "0  [36.66195147104413, 0.919602741008284, 23.6148...   \n",
       "3  [3.1389357931347757, 36.37367301229885, 10.385...   \n",
       "\n",
       "                                             n_score  \n",
       "0  [1.0, 0.02508330037299277, 0.644125315373835, ...  \n",
       "3  [0.0862969156860629, 1.0, 0.2855244271063499, ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# calculate the combined index\n",
    "#\n",
    "alpha = 0.5 # alpha is the proportion to assign to each score\n",
    "\n",
    "df_test['overall'] = df_test.scores * alpha + (1 - alpha) * df_test.n_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 00:    0.877 (586)\n",
      "Cluster: 01:    0.973 (548)\n",
      "Cluster: 02:    0.765 (377)\n",
      "Cluster: 03:    0.771 (375)\n",
      "Cluster: 04:    0.804 (354)\n",
      "Cluster: 05:    0.826 (317)\n",
      "Cluster: 06:    0.989 (287)\n",
      "Cluster: 07:    0.585 (275)\n",
      "Cluster: 08:    0.846 (242)\n",
      "Cluster: 09:    0.972 (200)\n",
      "Cluster: 10:    0.920 (200)\n",
      "Cluster: 11:    0.938 (184)\n",
      "Cluster: 12:    0.403 (169)\n",
      "Cluster: 13:    0.739 (155)\n",
      "Cluster: 14:    0.946 (108)\n",
      "Cluster: 15:    0.762 (99)\n",
      "Cluster: 16:    0.517 (104)\n",
      "Cluster: 17:    0.376 (62)\n",
      "Cluster: 18:    0.300 (43)\n"
     ]
    }
   ],
   "source": [
    "clusters = df_test.groupby('cluster')\n",
    "for cluster in clusters:\n",
    "    cluster_no = cluster[0]\n",
    "    cluster_df = cluster[1]\n",
    "    cluster_df['accuracy_score'] = cluster_df.overall.apply(lambda x: x[cluster_no])\n",
    "    # assume score is normalized\n",
    "    avg_score_for_cluster = cluster_df.accuracy_score.sum() / cluster_df.shape[0]\n",
    "    print(f\"Cluster: {cluster_no:02}: {avg_score_for_cluster:8.3f} ({cluster_df.shape[0]:02})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM = 0\n",
    "VECTOR = 1\n",
    "BOTH = 2\n",
    "def calculate_summary_stats(clusters_df: pd.DataFrame, method:int) -> dict[int,np.array]:\n",
    "    clusters = clusters_df.groupby('cluster')\n",
    "    table = {k:[] for k in range(df_test.cluster.max())}\n",
    "    for cluster in clusters:\n",
    "        cluster_no = cluster[0]\n",
    "        cluster_df = cluster[1]\n",
    "        row_count = cluster_df.shape[0]\n",
    "        values = np.zeros(row_count,dtype=float)\n",
    "        for row in range(row_count):\n",
    "            n_score = cluster_df.n_score.iloc[row][cluster_no]\n",
    "            m_score = cluster_df.scores.iloc[row][cluster_no]\n",
    "            if method == BM:\n",
    "                values[row] = m_score\n",
    "            elif method == VECTOR:\n",
    "                values[row] = n_score\n",
    "            else:\n",
    "                if n_score > m_score:\n",
    "                    values[row] = n_score\n",
    "                else:\n",
    "                    values[row] = m_score\n",
    "        table[cluster_no] = values\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00    0.759    0.014 (586)00    0.996    0.001 (586)00    0.998    0.001 (586)\n",
      "01    0.997    0.002 (548)01    0.950    0.004 (548)01    0.999    0.000 (548)\n",
      "02    0.658    0.016 (377)02    0.873    0.007 (377)02    0.919    0.006 (377)\n",
      "03    0.662    0.017 (375)03    0.879    0.008 (375)03    0.932    0.006 (375)\n",
      "04    0.707    0.015 (354)04    0.901    0.007 (354)04    0.918    0.007 (354)\n",
      "05    0.685    0.021 (317)05    0.967    0.004 (317)05    0.978    0.004 (317)\n",
      "06    0.992    0.004 (287)06    0.986    0.003 (287)06    0.998    0.001 (287)\n",
      "07    0.400    0.017 (275)07    0.770    0.010 (275)07    0.809    0.010 (275)\n",
      "08    0.746    0.018 (242)08    0.946    0.008 (242)08    0.966    0.006 (242)\n",
      "09    0.951    0.013 (200)09    0.993    0.004 (200)09    0.994    0.004 (200)\n",
      "10    0.874    0.016 (200)10    0.966    0.006 (200)10    0.983    0.004 (200)\n",
      "11    0.896    0.019 (184)11    0.979    0.007 (184)11    0.985    0.006 (184)\n",
      "12    0.221    0.012 (169)12    0.585    0.014 (169)12    0.598    0.014 (169)\n",
      "13    0.675    0.022 (155)13    0.803    0.017 (155)13    0.857    0.016 (155)\n",
      "14    0.994    0.006 (108)14    0.898    0.013 (108)14    0.995    0.005 (108)\n",
      "15    0.713    0.033 (99)15    0.810    0.022 (99)15    0.875    0.021 (99)\n",
      "16    0.450    0.030 (104)16    0.585    0.027 (104)16    0.652    0.027 (104)\n",
      "17    0.280    0.020 (62)17    0.473    0.024 (62)17    0.496    0.023 (62)\n",
      "18    0.189    0.017 (43)18    0.412    0.033 (43)18    0.430    0.030 (43)\n",
      "------------\n",
      "Ratio of both to BM25\n",
      "00   0.2\n",
      "01   5.3\n",
      "02   5.4\n",
      "03   6.0\n",
      "04   1.9\n",
      "05   1.2\n",
      "06   1.2\n",
      "07   5.1\n",
      "08   2.2\n",
      "09   0.1\n",
      "10   1.7\n",
      "11   0.6\n",
      "12   2.2\n",
      "13   6.7\n",
      "14  10.8\n",
      "15   8.0\n",
      "16  11.4\n",
      "17   4.8\n",
      "18   4.5\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "table_vector = calculate_summary_stats(df_test, VECTOR)\n",
    "table_match = calculate_summary_stats(df_test, BM)\n",
    "table_both = calculate_summary_stats(df_test, BOTH)\n",
    "for cluster in table_vector:\n",
    "    print(f\"{cluster:02} {table_vector[cluster].mean():8.3f} {stats.sem(table_vector[cluster]):8.3f} ({table_vector[cluster].size})\", end='')\n",
    "    print(f\"{cluster:02} {table_match[cluster].mean():8.3f} {stats.sem(table_match[cluster]):8.3f} ({table_match[cluster].size})\", end='')\n",
    "    print(f\"{cluster:02} {table_both[cluster].mean():8.3f} {stats.sem(table_both[cluster]):8.3f} ({table_both[cluster].size})\")\n",
    "print(\"--\" * 6)\n",
    "print(\"Ratio of both to BM25\")\n",
    "for cluster in table_vector:\n",
    "    print(f\"{cluster:02} {((table_both[cluster].mean()/table_match[cluster].mean())-1) * 100:5.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rankings\n",
    "\n",
    "Need to determine the rankings of scores for individual cells by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_scores( scores: dict[int, float] ) -> dict[int, float]:\n",
    "    \"\"\"\n",
    "    Givn a dictionary of floats, which represent scores, with integer keys, which represent clusters, \n",
    "    return a dictionary with the ranking of each float,\n",
    "    such that the items of the orginal disctionary are ordered from highest to lowest ranking.\n",
    "    \"\"\"\n",
    "    # print(\"received an dictionary of length\", len(scores))\n",
    "    x = sorted(scores, key=lambda x: scores[x], reverse=True)\n",
    "    ranks = list(range(len(scores)))\n",
    "    # print(f\"Scores:{scores}\")\n",
    "    # print(f\"x:{x}\")\n",
    "    # print(f\"Ranks:{ranks}\")\n",
    "    # print(f\"Dict:{dict(zip(ranks,x))}\")\n",
    "    return dict(zip(ranks, x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [2], 1: [1], 2: [0], 3: [3]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t={0:1,1:3,2:9,3:-1}\n",
    "r=rank_scores(t)\n",
    "result={0:[],1:[],2:[],3:[]}\n",
    "for k in result:\n",
    "    result[k].append(r[k])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [2, 2], 1: [1, 0], 2: [0, 1], 3: [3, 3]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t={0:5,1:3,2:9,3:-1}\n",
    "r=rank_scores(t)\n",
    "for k in result:\n",
    "    result[k].append(r[k])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>scores</th>\n",
       "      <th>rank_dict</th>\n",
       "      <th>ranked_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.5899505384390359, 0.7178018238587968, ...</td>\n",
       "      <td>{0: 1.0, 1: 0.5899505384390359, 2: 0.717801823...</td>\n",
       "      <td>{0: 1.0, 2: 0.7178018238587968, 7: 0.660227676...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.7138399779046296, 0.5878873131841577, ...</td>\n",
       "      <td>{0: 1.0, 1: 0.7138399779046296, 2: 0.587887313...</td>\n",
       "      <td>{0: 1.0, 3: 0.7325097113987431, 1: 0.713839977...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.7702480898652903, 0.7541705810199278, ...</td>\n",
       "      <td>{0: 1.0, 1: 0.7702480898652903, 2: 0.754170581...</td>\n",
       "      <td>{0: 1.0, 1: 0.7702480898652903, 2: 0.754170581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.8398823881416582, 0.911057325366115, 0...</td>\n",
       "      <td>{0: 1.0, 1: 0.8398823881416582, 2: 0.911057325...</td>\n",
       "      <td>{0: 1.0, 2: 0.911057325366115, 1: 0.8398823881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.4570903754579496, 0.4813372996722293, ...</td>\n",
       "      <td>{0: 1.0, 1: 0.4570903754579496, 2: 0.481337299...</td>\n",
       "      <td>{0: 1.0, 3: 0.5502696432774594, 7: 0.541632742...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.8107541827718205, 0.668534413005574, 0.8409...</td>\n",
       "      <td>{0: 0.8107541827718205, 1: 0.668534413005574, ...</td>\n",
       "      <td>{9: 1.0, 3: 0.9812789465880402, 12: 0.84136008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.4151818853067396, 0.4735370261830864, 0.463...</td>\n",
       "      <td>{0: 0.4151818853067396, 1: 0.4735370261830864,...</td>\n",
       "      <td>{9: 1.0, 7: 0.7027526327876555, 8: 0.530790532...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9362</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.55319222833124, 0.9212308952643732, 0.74075...</td>\n",
       "      <td>{0: 0.55319222833124, 1: 0.9212308952643732, 2...</td>\n",
       "      <td>{9: 1.0, 1: 0.9212308952643732, 2: 0.740751188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9367</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.4406033896961032, 0.49905886144795075, 0.48...</td>\n",
       "      <td>{0: 0.4406033896961032, 1: 0.49905886144795075...</td>\n",
       "      <td>{9: 1.0, 18: 0.8114921894190859, 16: 0.5878831...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9368</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.2190097163357121, 0.31411987364707994, 0.40...</td>\n",
       "      <td>{0: 0.2190097163357121, 1: 0.31411987364707994...</td>\n",
       "      <td>{9: 1.0, 5: 0.5684421173760053, 6: 0.474039873...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4685 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cluster                                             scores  \\\n",
       "0           0  [1.0, 0.5899505384390359, 0.7178018238587968, ...   \n",
       "3           0  [1.0, 0.7138399779046296, 0.5878873131841577, ...   \n",
       "7           0  [1.0, 0.7702480898652903, 0.7541705810199278, ...   \n",
       "9           0  [1.0, 0.8398823881416582, 0.911057325366115, 0...   \n",
       "13          0  [1.0, 0.4570903754579496, 0.4813372996722293, ...   \n",
       "...       ...                                                ...   \n",
       "9356       18  [0.8107541827718205, 0.668534413005574, 0.8409...   \n",
       "9358       18  [0.4151818853067396, 0.4735370261830864, 0.463...   \n",
       "9362       18  [0.55319222833124, 0.9212308952643732, 0.74075...   \n",
       "9367       18  [0.4406033896961032, 0.49905886144795075, 0.48...   \n",
       "9368       18  [0.2190097163357121, 0.31411987364707994, 0.40...   \n",
       "\n",
       "                                              rank_dict  \\\n",
       "0     {0: 1.0, 1: 0.5899505384390359, 2: 0.717801823...   \n",
       "3     {0: 1.0, 1: 0.7138399779046296, 2: 0.587887313...   \n",
       "7     {0: 1.0, 1: 0.7702480898652903, 2: 0.754170581...   \n",
       "9     {0: 1.0, 1: 0.8398823881416582, 2: 0.911057325...   \n",
       "13    {0: 1.0, 1: 0.4570903754579496, 2: 0.481337299...   \n",
       "...                                                 ...   \n",
       "9356  {0: 0.8107541827718205, 1: 0.668534413005574, ...   \n",
       "9358  {0: 0.4151818853067396, 1: 0.4735370261830864,...   \n",
       "9362  {0: 0.55319222833124, 1: 0.9212308952643732, 2...   \n",
       "9367  {0: 0.4406033896961032, 1: 0.49905886144795075...   \n",
       "9368  {0: 0.2190097163357121, 1: 0.31411987364707994...   \n",
       "\n",
       "                                            ranked_dict  \n",
       "0     {0: 1.0, 2: 0.7178018238587968, 7: 0.660227676...  \n",
       "3     {0: 1.0, 3: 0.7325097113987431, 1: 0.713839977...  \n",
       "7     {0: 1.0, 1: 0.7702480898652903, 2: 0.754170581...  \n",
       "9     {0: 1.0, 2: 0.911057325366115, 1: 0.8398823881...  \n",
       "13    {0: 1.0, 3: 0.5502696432774594, 7: 0.541632742...  \n",
       "...                                                 ...  \n",
       "9356  {9: 1.0, 3: 0.9812789465880402, 12: 0.84136008...  \n",
       "9358  {9: 1.0, 7: 0.7027526327876555, 8: 0.530790532...  \n",
       "9362  {9: 1.0, 1: 0.9212308952643732, 2: 0.740751188...  \n",
       "9367  {9: 1.0, 18: 0.8114921894190859, 16: 0.5878831...  \n",
       "9368  {9: 1.0, 5: 0.5684421173760053, 6: 0.474039873...  \n",
       "\n",
       "[4685 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_ranking_dict(a: np.array) -> dict[int, float]:\n",
    "    d = {}\n",
    "    for i in range(len(a)):\n",
    "        d[i] = a[i]\n",
    "    return d\n",
    "\n",
    "def sort_categories_by_values(categories: dict[int,float])->dict[int,float]:\n",
    "    return dict(sorted(categories.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "scores_df = test_df[[\"cluster\",\"scores\"]].copy()\n",
    "scores_df['rank_dict'] = scores_df.scores.apply(lambda x: create_ranking_dict(x))\n",
    "scores_df['ranked_dict'] = scores_df.rank_dict.apply(lambda x: sort_categories_by_values(x))\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9955418580639813,\n",
       " 1: 0.9496018413612536,\n",
       " 2: 0.8725218082845725,\n",
       " 3: 0.878967482367515,\n",
       " 4: 0.9010000744138762,\n",
       " 5: 0.9665182960469804,\n",
       " 6: 0.9863364147250021,\n",
       " 7: 0.7698907649900156,\n",
       " 8: 0.9455935808301014,\n",
       " 9: 0.993417848087002,\n",
       " 10: 0.9660563602155413,\n",
       " 11: 0.9793013893429433,\n",
       " 12: 0.5848580024494654,\n",
       " 13: 0.802920115081347,\n",
       " 14: 0.8979174590266658,\n",
       " 15: 0.8103387498342408,\n",
       " 16: 0.5851992604461563,\n",
       " 17: 0.4729533071389919,\n",
       " 18: 0.41168321206677216}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = scores_df.groupby('cluster')\n",
    "ranks = {}\n",
    "for cluster in clusters:\n",
    "    cluster_no = cluster[0]\n",
    "    cluster_df = cluster[1]\n",
    "    cluster_rank_total = 0\n",
    "    # if cluster_no > 0:\n",
    "        # break\n",
    "    cluster_df['cluster_rank'] = cluster_df.ranked_dict.apply(lambda x: x[cluster_no])\n",
    "    ranks[cluster_no] = cluster_df.cluster_rank.mean()\n",
    "\n",
    "ranks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>n_score</th>\n",
       "      <th>scores</th>\n",
       "      <th>max_score</th>\n",
       "      <th>rank_dict</th>\n",
       "      <th>ranked_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.02508330037299277, 0.644125315373835, ...</td>\n",
       "      <td>[1.0, 0.5899505384390359, 0.7178018238587968, ...</td>\n",
       "      <td>[1.0, 0.5899505384390359, 0.7178018238587968, ...</td>\n",
       "      <td>{0: 1.0, 1: 0.5899505384390359, 2: 0.717801823...</td>\n",
       "      <td>{0: 1.0, 2: 0.7178018238587968, 7: 0.660227676...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0862969156860629, 1.0, 0.2855244271063499, ...</td>\n",
       "      <td>[1.0, 0.7138399779046296, 0.5878873131841577, ...</td>\n",
       "      <td>[1.0, 1.0, 0.5878873131841577, 0.7325097113987...</td>\n",
       "      <td>{0: 1.0, 1: 1.0, 2: 0.5878873131841577, 3: 0.7...</td>\n",
       "      <td>{0: 1.0, 1: 1.0, 3: 0.7325097113987431, 5: 0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.2390495012663944, 0.309139184138737, 0...</td>\n",
       "      <td>[1.0, 0.7702480898652903, 0.7541705810199278, ...</td>\n",
       "      <td>[1.0, 0.7702480898652903, 0.7541705810199278, ...</td>\n",
       "      <td>{0: 1.0, 1: 0.7702480898652903, 2: 0.754170581...</td>\n",
       "      <td>{0: 1.0, 1: 0.7702480898652903, 2: 0.754170581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.41935515404995183, 0.608017202907...</td>\n",
       "      <td>[1.0, 0.8398823881416582, 0.911057325366115, 0...</td>\n",
       "      <td>[1.0, 0.8398823881416582, 0.911057325366115, 0...</td>\n",
       "      <td>{0: 1.0, 1: 0.8398823881416582, 2: 0.911057325...</td>\n",
       "      <td>{0: 1.0, 2: 0.911057325366115, 1: 0.8398823881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.1530411151107344, 0.6924163409636979, 0.772...</td>\n",
       "      <td>[1.0, 0.4570903754579496, 0.4813372996722293, ...</td>\n",
       "      <td>[1.0, 0.6924163409636979, 0.772080968257213, 1...</td>\n",
       "      <td>{0: 1.0, 1: 0.6924163409636979, 2: 0.772080968...</td>\n",
       "      <td>{0: 1.0, 3: 1.0, 2: 0.772080968257213, 1: 0.69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.0, 1.0, 0.22872164816940121, 0.028232366790...</td>\n",
       "      <td>[0.8107541827718205, 0.668534413005574, 0.8409...</td>\n",
       "      <td>[0.8107541827718205, 1.0, 0.8409176911235959, ...</td>\n",
       "      <td>{0: 0.8107541827718205, 1: 1.0, 2: 0.840917691...</td>\n",
       "      <td>{1: 1.0, 9: 1.0, 3: 0.9812789465880402, 12: 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.0, 0.45849926814538045, 0.0, 0.0, 0.5261163...</td>\n",
       "      <td>[0.4151818853067396, 0.4735370261830864, 0.463...</td>\n",
       "      <td>[0.4151818853067396, 0.4735370261830864, 0.463...</td>\n",
       "      <td>{0: 0.4151818853067396, 1: 0.4735370261830864,...</td>\n",
       "      <td>{9: 1.0, 7: 0.7027526327876555, 16: 0.56691893...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9362</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.0, 0.8417271844277981, 0.0, 0.0, 0.40321649...</td>\n",
       "      <td>[0.55319222833124, 0.9212308952643732, 0.74075...</td>\n",
       "      <td>[0.55319222833124, 0.9212308952643732, 0.74075...</td>\n",
       "      <td>{0: 0.55319222833124, 1: 0.9212308952643732, 2...</td>\n",
       "      <td>{9: 1.0, 1: 0.9212308952643732, 2: 0.740751188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9367</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.0, 1.0, 0.09962162318847063, 0.050075796234...</td>\n",
       "      <td>[0.4406033896961032, 0.49905886144795075, 0.48...</td>\n",
       "      <td>[0.4406033896961032, 1.0, 0.48995277969192114,...</td>\n",
       "      <td>{0: 0.4406033896961032, 1: 1.0, 2: 0.489952779...</td>\n",
       "      <td>{1: 1.0, 9: 1.0, 18: 0.8114921894190859, 16: 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9368</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.0, 1.0, 0.027277687739667104, 0.0, 0.527760...</td>\n",
       "      <td>[0.2190097163357121, 0.31411987364707994, 0.40...</td>\n",
       "      <td>[0.2190097163357121, 1.0, 0.4026339313209061, ...</td>\n",
       "      <td>{0: 0.2190097163357121, 1: 1.0, 2: 0.402633931...</td>\n",
       "      <td>{1: 1.0, 9: 1.0, 5: 0.5684421173760053, 4: 0.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4685 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cluster                                            n_score  \\\n",
       "0           0  [1.0, 0.02508330037299277, 0.644125315373835, ...   \n",
       "3           0  [0.0862969156860629, 1.0, 0.2855244271063499, ...   \n",
       "7           0  [1.0, 0.2390495012663944, 0.309139184138737, 0...   \n",
       "9           0  [1.0, 0.0, 0.41935515404995183, 0.608017202907...   \n",
       "13          0  [0.1530411151107344, 0.6924163409636979, 0.772...   \n",
       "...       ...                                                ...   \n",
       "9356       18  [0.0, 1.0, 0.22872164816940121, 0.028232366790...   \n",
       "9358       18  [0.0, 0.45849926814538045, 0.0, 0.0, 0.5261163...   \n",
       "9362       18  [0.0, 0.8417271844277981, 0.0, 0.0, 0.40321649...   \n",
       "9367       18  [0.0, 1.0, 0.09962162318847063, 0.050075796234...   \n",
       "9368       18  [0.0, 1.0, 0.027277687739667104, 0.0, 0.527760...   \n",
       "\n",
       "                                                 scores  \\\n",
       "0     [1.0, 0.5899505384390359, 0.7178018238587968, ...   \n",
       "3     [1.0, 0.7138399779046296, 0.5878873131841577, ...   \n",
       "7     [1.0, 0.7702480898652903, 0.7541705810199278, ...   \n",
       "9     [1.0, 0.8398823881416582, 0.911057325366115, 0...   \n",
       "13    [1.0, 0.4570903754579496, 0.4813372996722293, ...   \n",
       "...                                                 ...   \n",
       "9356  [0.8107541827718205, 0.668534413005574, 0.8409...   \n",
       "9358  [0.4151818853067396, 0.4735370261830864, 0.463...   \n",
       "9362  [0.55319222833124, 0.9212308952643732, 0.74075...   \n",
       "9367  [0.4406033896961032, 0.49905886144795075, 0.48...   \n",
       "9368  [0.2190097163357121, 0.31411987364707994, 0.40...   \n",
       "\n",
       "                                              max_score  \\\n",
       "0     [1.0, 0.5899505384390359, 0.7178018238587968, ...   \n",
       "3     [1.0, 1.0, 0.5878873131841577, 0.7325097113987...   \n",
       "7     [1.0, 0.7702480898652903, 0.7541705810199278, ...   \n",
       "9     [1.0, 0.8398823881416582, 0.911057325366115, 0...   \n",
       "13    [1.0, 0.6924163409636979, 0.772080968257213, 1...   \n",
       "...                                                 ...   \n",
       "9356  [0.8107541827718205, 1.0, 0.8409176911235959, ...   \n",
       "9358  [0.4151818853067396, 0.4735370261830864, 0.463...   \n",
       "9362  [0.55319222833124, 0.9212308952643732, 0.74075...   \n",
       "9367  [0.4406033896961032, 1.0, 0.48995277969192114,...   \n",
       "9368  [0.2190097163357121, 1.0, 0.4026339313209061, ...   \n",
       "\n",
       "                                              rank_dict  \\\n",
       "0     {0: 1.0, 1: 0.5899505384390359, 2: 0.717801823...   \n",
       "3     {0: 1.0, 1: 1.0, 2: 0.5878873131841577, 3: 0.7...   \n",
       "7     {0: 1.0, 1: 0.7702480898652903, 2: 0.754170581...   \n",
       "9     {0: 1.0, 1: 0.8398823881416582, 2: 0.911057325...   \n",
       "13    {0: 1.0, 1: 0.6924163409636979, 2: 0.772080968...   \n",
       "...                                                 ...   \n",
       "9356  {0: 0.8107541827718205, 1: 1.0, 2: 0.840917691...   \n",
       "9358  {0: 0.4151818853067396, 1: 0.4735370261830864,...   \n",
       "9362  {0: 0.55319222833124, 1: 0.9212308952643732, 2...   \n",
       "9367  {0: 0.4406033896961032, 1: 1.0, 2: 0.489952779...   \n",
       "9368  {0: 0.2190097163357121, 1: 1.0, 2: 0.402633931...   \n",
       "\n",
       "                                            ranked_dict  \n",
       "0     {0: 1.0, 2: 0.7178018238587968, 7: 0.660227676...  \n",
       "3     {0: 1.0, 1: 1.0, 3: 0.7325097113987431, 5: 0.7...  \n",
       "7     {0: 1.0, 1: 0.7702480898652903, 2: 0.754170581...  \n",
       "9     {0: 1.0, 2: 0.911057325366115, 1: 0.8398823881...  \n",
       "13    {0: 1.0, 3: 1.0, 2: 0.772080968257213, 1: 0.69...  \n",
       "...                                                 ...  \n",
       "9356  {1: 1.0, 9: 1.0, 3: 0.9812789465880402, 12: 0....  \n",
       "9358  {9: 1.0, 7: 0.7027526327876555, 16: 0.56691893...  \n",
       "9362  {9: 1.0, 1: 0.9212308952643732, 2: 0.740751188...  \n",
       "9367  {1: 1.0, 9: 1.0, 18: 0.8114921894190859, 16: 0...  \n",
       "9368  {1: 1.0, 9: 1.0, 5: 0.5684421173760053, 4: 0.5...  \n",
       "\n",
       "[4685 rows x 6 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = test_df[[\"cluster\",\"n_score\",\"scores\"]].copy()\n",
    "scores_df['max_score'] = scores_df.apply(lambda row: np.maximum(row['n_score'], row['scores']), axis=1)\n",
    "scores_df['rank_dict'] = scores_df.max_score.apply(lambda x: create_ranking_dict(x))\n",
    "scores_df['ranked_dict'] = scores_df.rank_dict.apply(lambda x: sort_categories_by_values(x))\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586:    0.998    0.017\n",
      "548:    0.999    0.009\n",
      "377:    0.919    0.109\n",
      "375:    0.932    0.121\n",
      "354:    0.918    0.127\n",
      "317:    0.978    0.070\n",
      "287:    0.998    0.023\n",
      "275:    0.809    0.159\n",
      "242:    0.966    0.091\n",
      "200:    0.994    0.050\n",
      "200:    0.983    0.052\n",
      "184:    0.985    0.080\n",
      "169:    0.598    0.182\n",
      "155:    0.857    0.194\n",
      "108:    0.995    0.049\n",
      "99:    0.875    0.207\n",
      "104:    0.652    0.276\n",
      "62:    0.496    0.180\n",
      "43:    0.430    0.198\n"
     ]
    }
   ],
   "source": [
    "clusters = scores_df.groupby('cluster')\n",
    "ranks = {}\n",
    "for cluster in clusters:\n",
    "    cluster_no = cluster[0]\n",
    "    cluster_df = cluster[1]\n",
    "    cluster_rank_total = 0\n",
    "    cluster_df['cluster_rank'] = cluster_df.ranked_dict.apply(lambda x: x[cluster_no])\n",
    "    ranks[cluster_no] = (cluster_df.cluster_rank.mean(), cluster_df.cluster_rank.std(), cluster_df.cluster_rank.count())\n",
    "\n",
    "for rank in ranks.values():\n",
    "    print(f\"{rank[2]}: {rank[0]:8.3f} {rank[1]:8.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
