{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25\n",
    "\n",
    "Approach to cluster matching built primarily around BM25, using material from fusion.ipynb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# import libraries\n",
    "#\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from typing import Union\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# set constants\n",
    "#\n",
    "input_path = Path(\"../results\")\n",
    "output_path = Path(\"../results\")\n",
    "\n",
    "training_fraction = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 9370\n",
      "training set has 7496 rows\n",
      "test set has 1874 rows\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# load the data along with embeddings\n",
    "#\n",
    "master_df = pd.read_csv(input_path / Path(\"ragsc_00_all_large.csv\"))\n",
    "master_n_cells = master_df.shape[0]\n",
    "\n",
    "train_df = master_df.sample(frac=training_fraction)\n",
    "test_df = master_df.drop(train_df.index)  # .sample(frac=training_fraction)\n",
    "print(f\"total rows: {master_df.shape[0]}\")\n",
    "print(f\"training set has {train_df.shape[0]} rows\")\n",
    "print(f\"test set has {test_df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_bags(df: pd.DataFrame, max_genes: int, sort_by_cluster_names=True) -> dict:\n",
    "    \"\"\"\n",
    "    Produces \"bags of words\" for each cluster to use as documents in BM25 analysis.\n",
    "\n",
    "    Returns a dictionary with cluster name as the keys and a list of gene names as the values.\n",
    "    \"\"\"\n",
    "    clusters = df.groupby(\"cluster\", sort=False)\n",
    "    word_dict = {}\n",
    "    for cluster in clusters:\n",
    "        # each cluster is a tuple (cluster name, cluster dataframe)\n",
    "        words = []\n",
    "        cluster_df = cluster[1]  # the dataframe\n",
    "        # convert each signature into a list of string\n",
    "        word_series = cluster_df.signature.apply(lambda x: x.split(\" \"))\n",
    "        # create a bag of words based containing the gene names for this cluster\n",
    "        for sig in word_series:\n",
    "            # retain only max_genes gene names to add to the bag of words\n",
    "            words.extend(sig[:max_genes])\n",
    "        word_dict[cluster[0]] = words\n",
    "    if sort_by_cluster_names:\n",
    "        word_dict = {k: word_dict[k] for k in sorted(word_dict)}\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# chunking\n",
    "#\n",
    "def chunk(s: Union[str, list], size: int, step=1) -> list[str]:\n",
    "    \"\"\"\n",
    "    Takes a string or list of strings and creates a list of overlapping chunks of a given size.\n",
    "\n",
    "    Args\n",
    "        size: The number of words (gene names) in each chunk.\n",
    "        step: The number of words to advance before the next chunk (defaults to 1).\n",
    "    Returns\n",
    "        A list of strings representing the chunks.\n",
    "    \"\"\"\n",
    "    if isinstance(s, str):\n",
    "        a = s.split()\n",
    "    else:\n",
    "        a = s\n",
    "    results = []\n",
    "    max = len(a)\n",
    "    for i in range(max):\n",
    "        if i + size < max:\n",
    "            results.append(\" \".join(a[i : i + size]))\n",
    "        else:\n",
    "            results.append(\" \".join(a[i:]))\n",
    "        i += step\n",
    "    return results\n",
    "\n",
    "\n",
    "chunk2 = partial(chunk, size=2)\n",
    "chunk3 = partial(chunk, size=2, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_sig(sig: str, chunk_size: int, overlap=3) -> list[str]:\n",
    "    if isinstance(sig, str):\n",
    "        items = sig.split()\n",
    "    else:\n",
    "        items = sig\n",
    "    chunks = []\n",
    "    items = sig.split(\" \")\n",
    "    for i in range(0, len(items), overlap):\n",
    "        if i + chunk_size > len(items):\n",
    "            chunks.append(\" \".join(items[i:]))\n",
    "            break\n",
    "        else:\n",
    "            chunks.append(\" \".join(items[i : i + chunk_size]))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = get_gene_bags(train_df, max_genes=120)\n",
    "chunk_size = 3\n",
    "docs = [chunk_sig(\" \".join(x), chunk_size, chunk_size) for x in word_dict.values()]\n",
    "bm25_index=BM25Okapi(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RPL11 CAMK4 RIPOR2',\n",
       " 'AC079793.1 SF3B1 RPSA',\n",
       " 'RPL29 CBLB RPS12',\n",
       " 'JAK2 SYNE2 PPP2R5C',\n",
       " 'SLTM ANKRD12 RPRD1A',\n",
       " 'CCNL2 RPL22 TNFRSF1B',\n",
       " 'EPB41 ZMYM4 NDUFS5',\n",
       " 'TM2D1 JAK1 USP33',\n",
       " 'SELENOF CD53 CD2',\n",
       " 'TXNIP RPS27 KIFAP3']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(bm25, gene_list, max_genes=25, normalized=True) -> list[float]:\n",
    "    \"\"\"\n",
    "    Returns a list containing the scores for a particular list of genes\n",
    "    \"\"\"\n",
    "    query = chunk_sig(gene_list, chunk_size)[:max_genes]\n",
    "    scores = bm25.get_scores(query)\n",
    "    if (np.max(scores) <= np.min(scores)):\n",
    "        print(\"max and min are equal!\")\n",
    "        return scores\n",
    "    if normalized:\n",
    "        scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_score_column(df: pd.DataFrame, bm25, max_genes) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a column to the provided dataframe containing the BM25 scores.\n",
    "\n",
    "    Args:\n",
    "        df - the dataframe whose signatures will be used to generate the scores\n",
    "        bm25 - the index to use fo comparison\n",
    "        max_genes - the maximum number of genes to include from each signature\n",
    "\n",
    "    Returns a reference to the original dataframe\n",
    "    \"\"\"\n",
    "    df[\"scores\"] = df.signature.apply(lambda x: get_score(bm25, x, max_genes))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max and min are equal!\n",
      "max and min are equal!\n",
      "max and min are equal!\n",
      "max and min are equal!\n",
      "max and min are equal!\n"
     ]
    }
   ],
   "source": [
    "df_test = create_score_column(test_df, bm25_index, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM = 0\n",
    "VECTOR = 1\n",
    "BOTH = 2\n",
    "\n",
    "\n",
    "def calculate_summary_stats(\n",
    "    clusters_df: pd.DataFrame, method: int\n",
    ") -> dict[int, np.ndarray]:\n",
    "    clusters = clusters_df.groupby(\"cluster\")\n",
    "    table: dict[int, np.ndarray] = {k: [] for k in range(df_test.cluster.max())}  # type: ignore\n",
    "    for cluster in clusters:\n",
    "        cluster_no = cluster[0]\n",
    "        cluster_df = cluster[1]\n",
    "        row_count = cluster_df.shape[0]\n",
    "        values = np.zeros(row_count, dtype=float)\n",
    "        for row in range(row_count):\n",
    "            # n_score = cluster_df.n_score.iloc[row][cluster_no]\n",
    "            m_score = cluster_df.scores.iloc[row][cluster_no]\n",
    "            if method == BM:\n",
    "                values[row] = m_score\n",
    "            else:\n",
    "                logger.error(\"Only supports BM25 stats\")\n",
    "            # elif method == VECTOR:\n",
    "            #     values[row] = n_score\n",
    "            # else:\n",
    "            #     if n_score > m_score:\n",
    "            #         values[row] = n_score\n",
    "            #     else:\n",
    "            #         values[row] = m_score\n",
    "        table[cluster_no] = values  # type: ignore\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00    0.553    0.377    0.023 (259)\n",
      "01    0.361    0.245    0.017 (203)\n",
      "02    0.562    0.354    0.029 (155)\n",
      "03    0.574    0.321    0.026 (155)\n",
      "04    0.433    0.319    0.027 (144)\n",
      "05    0.610    0.384    0.035 (122)\n",
      "06    0.495    0.342    0.036 (89)\n",
      "07    0.408    0.346    0.034 (106)\n",
      "08    0.504    0.401    0.038 (112)\n",
      "09    0.613    0.384    0.042 (84)\n",
      "10    0.558    0.375    0.045 (70)\n",
      "11    0.533    0.420    0.050 (72)\n",
      "12    0.261    0.336    0.043 (63)\n",
      "13    0.386    0.388    0.047 (69)\n",
      "14    0.224    0.325    0.051 (42)\n",
      "15    0.315    0.394    0.064 (39)\n",
      "16    0.160    0.268    0.042 (41)\n",
      "17    0.226    0.348    0.067 (28)\n",
      "18    0.117    0.290    0.065 (21)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "table_match = calculate_summary_stats(df_test, BM)\n",
    "for cluster in table_match:\n",
    "    print(\n",
    "        f\"{cluster:02} {table_match[cluster].mean():8.3f} {table_match[cluster].std():8.3f} {stats.sem(table_match[cluster]):8.3f} ({table_match[cluster].size})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>scores</th>\n",
       "      <th>rank_dict</th>\n",
       "      <th>ranked_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.8317565093984453, 0.8898878992585331, 0.600...</td>\n",
       "      <td>{0: 0.8317565093984453, 1: 0.8898878992585331,...</td>\n",
       "      <td>{3: 1.0, 1: 0.8898878992585331, 0: 0.831756509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.7101401168618983, 0.7080276093736951, ...</td>\n",
       "      <td>{0: 1.0, 1: 0.7101401168618983, 2: 0.708027609...</td>\n",
       "      <td>{0: 1.0, 1: 0.7101401168618983, 2: 0.708027609...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.6582289843957945, 0.7078091830170901, ...</td>\n",
       "      <td>{0: 1.0, 1: 0.6582289843957945, 2: 0.707809183...</td>\n",
       "      <td>{0: 1.0, 2: 0.7078091830170901, 1: 0.658228984...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.9293668223785776, 1.0, 0.8694028139139268, ...</td>\n",
       "      <td>{0: 0.9293668223785776, 1: 1.0, 2: 0.869402813...</td>\n",
       "      <td>{1: 1.0, 0: 0.9293668223785776, 2: 0.869402813...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.8597027800415953, 0.6926143798962348, ...</td>\n",
       "      <td>{0: 1.0, 1: 0.8597027800415953, 2: 0.692614379...</td>\n",
       "      <td>{0: 1.0, 1: 0.8597027800415953, 3: 0.693894467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.530859651465067, 0.5230712082127268, 0.4165...</td>\n",
       "      <td>{0: 0.530859651465067, 1: 0.5230712082127268, ...</td>\n",
       "      <td>{9: 1.0, 0: 0.530859651465067, 1: 0.5230712082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9349</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.7309076969354257, 1.0, 0.7209908954735146, ...</td>\n",
       "      <td>{0: 0.7309076969354257, 1: 1.0, 2: 0.720990895...</td>\n",
       "      <td>{1: 1.0, 3: 0.9982068555527103, 4: 0.902158389...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9361</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.8926251895220338, 0.6465804935882411, 0.721...</td>\n",
       "      <td>{0: 0.8926251895220338, 1: 0.6465804935882411,...</td>\n",
       "      <td>{9: 1.0, 0: 0.8926251895220338, 3: 0.776211615...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9365</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.758851489432163, 0.41861073375775426, 0.572...</td>\n",
       "      <td>{0: 0.758851489432163, 1: 0.41861073375775426,...</td>\n",
       "      <td>{9: 1.0, 0: 0.758851489432163, 5: 0.7457135315...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9369</th>\n",
       "      <td>18</td>\n",
       "      <td>[1.0, 0.4508563820465382, 0.5054983079875476, ...</td>\n",
       "      <td>{0: 1.0, 1: 0.4508563820465382, 2: 0.505498307...</td>\n",
       "      <td>{0: 1.0, 9: 0.6088541685302671, 5: 0.593459602...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1874 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cluster                                             scores  \\\n",
       "12          0  [0.8317565093984453, 0.8898878992585331, 0.600...   \n",
       "16          0  [1.0, 0.7101401168618983, 0.7080276093736951, ...   \n",
       "17          0  [1.0, 0.6582289843957945, 0.7078091830170901, ...   \n",
       "18          0  [0.9293668223785776, 1.0, 0.8694028139139268, ...   \n",
       "25          0  [1.0, 0.8597027800415953, 0.6926143798962348, ...   \n",
       "...       ...                                                ...   \n",
       "9347       18  [0.530859651465067, 0.5230712082127268, 0.4165...   \n",
       "9349       18  [0.7309076969354257, 1.0, 0.7209908954735146, ...   \n",
       "9361       18  [0.8926251895220338, 0.6465804935882411, 0.721...   \n",
       "9365       18  [0.758851489432163, 0.41861073375775426, 0.572...   \n",
       "9369       18  [1.0, 0.4508563820465382, 0.5054983079875476, ...   \n",
       "\n",
       "                                              rank_dict  \\\n",
       "12    {0: 0.8317565093984453, 1: 0.8898878992585331,...   \n",
       "16    {0: 1.0, 1: 0.7101401168618983, 2: 0.708027609...   \n",
       "17    {0: 1.0, 1: 0.6582289843957945, 2: 0.707809183...   \n",
       "18    {0: 0.9293668223785776, 1: 1.0, 2: 0.869402813...   \n",
       "25    {0: 1.0, 1: 0.8597027800415953, 2: 0.692614379...   \n",
       "...                                                 ...   \n",
       "9347  {0: 0.530859651465067, 1: 0.5230712082127268, ...   \n",
       "9349  {0: 0.7309076969354257, 1: 1.0, 2: 0.720990895...   \n",
       "9361  {0: 0.8926251895220338, 1: 0.6465804935882411,...   \n",
       "9365  {0: 0.758851489432163, 1: 0.41861073375775426,...   \n",
       "9369  {0: 1.0, 1: 0.4508563820465382, 2: 0.505498307...   \n",
       "\n",
       "                                            ranked_dict  \n",
       "12    {3: 1.0, 1: 0.8898878992585331, 0: 0.831756509...  \n",
       "16    {0: 1.0, 1: 0.7101401168618983, 2: 0.708027609...  \n",
       "17    {0: 1.0, 2: 0.7078091830170901, 1: 0.658228984...  \n",
       "18    {1: 1.0, 0: 0.9293668223785776, 2: 0.869402813...  \n",
       "25    {0: 1.0, 1: 0.8597027800415953, 3: 0.693894467...  \n",
       "...                                                 ...  \n",
       "9347  {9: 1.0, 0: 0.530859651465067, 1: 0.5230712082...  \n",
       "9349  {1: 1.0, 3: 0.9982068555527103, 4: 0.902158389...  \n",
       "9361  {9: 1.0, 0: 0.8926251895220338, 3: 0.776211615...  \n",
       "9365  {9: 1.0, 0: 0.758851489432163, 5: 0.7457135315...  \n",
       "9369  {0: 1.0, 9: 0.6088541685302671, 5: 0.593459602...  \n",
       "\n",
       "[1874 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_ranking_dict(a: np.ndarray) -> dict[int, float]:\n",
    "    d = {}\n",
    "    for i in range(len(a)):\n",
    "        d[i] = a[i]\n",
    "    return d\n",
    "\n",
    "\n",
    "def sort_categories_by_values(categories: dict[int, float]) -> dict[int, float]:\n",
    "    return dict(sorted(categories.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "\n",
    "scores_df = test_df[[\"cluster\", \"scores\"]].copy()\n",
    "scores_df[\"rank_dict\"] = scores_df.scores.apply(lambda x: create_ranking_dict(x))\n",
    "scores_df[\"ranked_dict\"] = scores_df.rank_dict.apply(\n",
    "    lambda x: sort_categories_by_values(x)\n",
    ")\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9962871030604834,\n",
       " 1: 0.9746683182640282,\n",
       " 2: 0.8886388823094608,\n",
       " 3: 0.8839024385738254,\n",
       " 4: 0.9238078474246274,\n",
       " 5: 0.9707897654283968,\n",
       " 6: 0.994977867743239,\n",
       " 7: 0.8134663432133056,\n",
       " 8: 0.9379237116862214,\n",
       " 9: 0.9908841366830422,\n",
       " 10: 0.9758680944604559,\n",
       " 11: 0.9849142655251698,\n",
       " 12: 0.6571824004441252,\n",
       " 13: 0.8753256053082086,\n",
       " 14: 0.9075333920329774,\n",
       " 15: 0.8192226911974294,\n",
       " 16: 0.7413395902884095,\n",
       " 17: 0.43202495874237967,\n",
       " 18: 0.48441904200836944}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = scores_df.groupby(\"cluster\")\n",
    "ranks = {}\n",
    "for cluster in clusters:\n",
    "    cluster_no = cluster[0]\n",
    "    cluster_df = cluster[1]\n",
    "    cluster_rank_total = 0\n",
    "    # if cluster_no > 0:\n",
    "    # break\n",
    "    cluster_df[\"cluster_rank\"] = cluster_df.ranked_dict.apply(lambda x: x[cluster_no])\n",
    "    ranks[cluster_no] = cluster_df.cluster_rank.mean()\n",
    "\n",
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00      234      247     0.95\n",
      "01      158      206     0.77\n",
      "02       59      166     0.36\n",
      "03       62      153     0.41\n",
      "04       86      160     0.54\n",
      "05       99      127     0.78\n",
      "06       88       93     0.95\n",
      "07       17       99     0.17\n",
      "08       66       95     0.69\n",
      "09       75       81     0.93\n",
      "10       76       90     0.84\n",
      "11       68       73     0.93\n",
      "12        1       55     0.02\n",
      "13       27       51     0.53\n",
      "14       26       52     0.50\n",
      "15       18       50     0.36\n",
      "16        9       32     0.28\n",
      "17        0       30     0.00\n",
      "18        0       14     0.00\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# need to calculate the rank agreement between the actual cluster and the top ranked predicted cluster\n",
    "#\n",
    "\n",
    "\n",
    "def correct_ranking(cluster_no, ranked_dict) -> int:\n",
    "    pred_clusters = list(ranked_dict.keys())\n",
    "    if pred_clusters[0] == cluster_no:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "clusters = scores_df.groupby(\"cluster\")\n",
    "ranks = {}\n",
    "for cluster in clusters:\n",
    "    cluster_no = cluster[0]\n",
    "    cluster_df = cluster[1]\n",
    "    cluster_df[\"ranked_correctly\"] = cluster_df.apply(\n",
    "        lambda row: correct_ranking(cluster_no, row[\"ranked_dict\"]), axis=1\n",
    "    )  # type:ignore\n",
    "\n",
    "    print(\n",
    "        f\"{cluster_no:02} {cluster_df.ranked_correctly.sum():8} {cluster_df.shape[0]:8} {cluster_df.ranked_correctly.mean():8.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1212\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# test chunking approach\n",
    "#\n",
    "sig1 = test_df.signature.iloc[0]\n",
    "print(len(sig1))\n",
    "print(type(sig1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SKAP1 HS2ST1 RPL5 EIF2AK3', 'HS2ST1 RPL5 EIF2AK3 GLS', 'RPL5 EIF2AK3 GLS LRRFIP2', 'EIF2AK3 GLS LRRFIP2 HCLS1', 'GLS LRRFIP2 HCLS1 STAG1', 'LRRFIP2 HCLS1 STAG1 ERCC8', 'HCLS1 STAG1 ERCC8 HLA-DRB1', 'STAG1 ERCC8 HLA-DRB1 UBE3C', 'ERCC8 HLA-DRB1 UBE3C RPL30', 'HLA-DRB1 UBE3C RPL30 WAPL', 'UBE3C RPL30 WAPL PICALM', 'RPL30 WAPL PICALM CLEC2D', 'WAPL PICALM CLEC2D SYNE2', 'PICALM CLEC2D SYNE2 CCL5', 'CLEC2D SYNE2 CCL5 SMCHD1', 'SYNE2 CCL5 SMCHD1 RNF138', 'CCL5 SMCHD1 RNF138 STK4', 'SMCHD1 RNF138 STK4 KDM1A', 'RNF138 STK4 KDM1A RPL11', 'STK4 KDM1A RPL11 SRSF4', 'KDM1A RPL11 SRSF4 PTP4A2', 'RPL11 SRSF4 PTP4A2 KHDRBS1', 'SRSF4 PTP4A2 KHDRBS1 RPS8', 'PTP4A2 KHDRBS1 RPS8 NASP', 'KHDRBS1 RPS8 NASP FAF1', 'RPS8 NASP FAF1 SSBP3', 'NASP FAF1 SSBP3 PRKACB', 'FAF1 SSBP3 PRKACB SLC30A7', 'SSBP3 PRKACB SLC30A7 PRPF38B', 'PRKACB SLC30A7 PRPF38B CD53', 'SLC30A7 PRPF38B CD53 CD2', 'PRPF38B CD53 CD2 RCOR3', 'CD53 CD2 RCOR3 ANGEL2', 'CD2 RCOR3 ANGEL2 LPIN1', 'RCOR3 ANGEL2 LPIN1 EML4', 'ANGEL2 LPIN1 EML4 PSME4', 'LPIN1 EML4 PSME4 USP34', 'EML4 PSME4 USP34 COMMD1', 'PSME4 USP34 COMMD1 SNRPG', 'USP34 COMMD1 SNRPG CXCR4', 'COMMD1 SNRPG CXCR4 MBD5', 'SNRPG CXCR4 MBD5 TLK1', 'CXCR4 MBD5 TLK1 SP3', 'MBD5 TLK1 SP3 CUL3', 'TLK1 SP3 CUL3 PTMA', 'SP3 CUL3 PTMA SETD5', 'CUL3 PTMA SETD5 ARHGEF3', 'PTMA SETD5 ARHGEF3 CGGBP1', 'SETD5 ARHGEF3 CGGBP1 TBC1D23', 'ARHGEF3 CGGBP1 TBC1D23 KPNA1', 'CGGBP1 TBC1D23 KPNA1 SLC9A9', 'TBC1D23 KPNA1 SLC9A9 KPNA4', 'KPNA1 SLC9A9 KPNA4 KLHL24', 'SLC9A9 KPNA4 KLHL24 ACAP2', 'KPNA4 KLHL24 ACAP2 ZNF718', 'KLHL24 ACAP2 ZNF718 SRP72', 'ACAP2 ZNF718 SRP72 AFF1', 'ZNF718 SRP72 AFF1 GPRIN3', 'SRP72 AFF1 GPRIN3 DNAJB14', 'AFF1 GPRIN3 DNAJB14 RPL34', 'GPRIN3 DNAJB14 RPL34 ARHGAP10', 'DNAJB14 RPL34 ARHGAP10 LRBA', 'RPL34 ARHGAP10 LRBA FBXW7', 'ARHGAP10 LRBA FBXW7 MTMR12', 'LRBA FBXW7 MTMR12 BTF3', 'FBXW7 MTMR12 BTF3 AP3B1', 'MTMR12 BTF3 AP3B1 MSH3', 'BTF3 AP3B1 MSH3 PPIP5K2', 'AP3B1 MSH3 PPIP5K2 MAN2A1', 'MSH3 PPIP5K2 MAN2A1 ARHGAP26', 'PPIP5K2 MAN2A1 ARHGAP26 FBXO38', 'MAN2A1 ARHGAP26 FBXO38 ITK', 'ARHGAP26 FBXO38 ITK NPM1', 'FBXO38 ITK NPM1 HNRNPH1', 'ITK NPM1 HNRNPH1 RNF130', 'NPM1 HNRNPH1 RNF130 RACK1', 'HNRNPH1 RNF130 RACK1 EXOC2', 'RNF130 RACK1 EXOC2 HIST1H4C', 'RACK1 EXOC2 HIST1H4C HLA-F', 'EXOC2 HIST1H4C HLA-F HLA-C', 'HIST1H4C HLA-F HLA-C FYN', 'HLA-F HLA-C FYN THEMIS', 'HLA-C FYN THEMIS EPB41L2', 'FYN THEMIS EPB41L2 SYNE1', 'THEMIS EPB41L2 SYNE1 ARID1B', 'EPB41L2 SYNE1 ARID1B MAD1L1', 'SYNE1 ARID1B MAD1L1 CARD11', 'ARID1B MAD1L1 CARD11 FOXK1', 'MAD1L1 CARD11 FOXK1 COA1', 'CARD11 FOXK1 COA1 OGDH', 'FOXK1 COA1 OGDH PRKRIP1', 'COA1 OGDH PRKRIP1 SRPK2', 'OGDH PRKRIP1 SRPK2 MKLN1', 'PRKRIP1 SRPK2 MKLN1 GIMAP4', 'SRPK2 MKLN1 GIMAP4 PRKDC', 'MKLN1 GIMAP4 PRKDC RB1CC1', 'GIMAP4 PRKDC RB1CC1 ATP6V1H', 'PRKDC RB1CC1 ATP6V1H NCOA2', 'RB1CC1 ATP6V1H NCOA2 YWHAZ', 'ATP6V1H NCOA2 YWHAZ NCALD', 'NCOA2 YWHAZ NCALD SNTB1', 'YWHAZ NCALD SNTB1 KDM4C', 'NCALD SNTB1 KDM4C TLE4', 'SNTB1 KDM4C TLE4 AGTPBP1', 'KDM4C TLE4 AGTPBP1 NAA35', 'TLE4 AGTPBP1 NAA35 ATP6V1G1', 'AGTPBP1 NAA35 ATP6V1G1 MVB12B', 'NAA35 ATP6V1G1 MVB12B MPP7', 'ATP6V1G1 MVB12B MPP7 SMC3', 'MVB12B MPP7 SMC3 EIF3A', 'MPP7 SMC3 EIF3A CD81', 'SMC3 EIF3A CD81 TRIM22', 'EIF3A CD81 TRIM22 PSMA1', 'CD81 TRIM22 PSMA1 C11orf58', 'TRIM22 PSMA1 C11orf58 RPS13', 'PSMA1 C11orf58 RPS13 EXT2', 'C11orf58 RPS13 EXT2 FNBP4', 'RPS13 EXT2 FNBP4 CFL1', 'EXT2 FNBP4 CFL1 PACS1', 'FNBP4 CFL1 PACS1 EMSY', 'CFL1 PACS1 EMSY CTSC', 'PACS1 EMSY CTSC MED17', 'EMSY CTSC MED17 CD3G', 'CTSC MED17 CD3G KRAS', 'MED17 CD3G KRAS ERGIC2', 'CD3G KRAS ERGIC2 ARID2', 'KRAS ERGIC2 ARID2 USP15', 'ERGIC2 ARID2 USP15 MSRB3', 'ARID2 USP15 MSRB3 CNOT2', 'USP15 MSRB3 CNOT2 CEP290', 'MSRB3 CNOT2 CEP290 SPPL3', 'CNOT2 CEP290 SPPL3 HMGB1', 'CEP290 SPPL3 HMGB1 ELF1', 'SPPL3 HMGB1 ELF1 LCP1', 'HMGB1 ELF1 LCP1 KLF12', 'ELF1 LCP1 KLF12 TPP2', 'LCP1 KLF12 TPP2 NUBPL', 'KLF12 TPP2 NUBPL PPP2R3C', 'TPP2 NUBPL PPP2R3C RPS29', 'NUBPL PPP2R3C RPS29 DDHD1', 'PPP2R3C RPS29 DDHD1 MAPK1IP1L', 'RPS29 DDHD1 MAPK1IP1L PRKCH', 'DDHD1 MAPK1IP1L PRKCH SNW1', 'MAPK1IP1L PRKCH SNW1 LINC02328', 'PRKCH SNW1 LINC02328 DGLUCY', 'SNW1 LINC02328 DGLUCY RASGRP1', 'LINC02328 DGLUCY RASGRP1 FAM214A', 'DGLUCY RASGRP1 FAM214A HERC1', 'RASGRP1 FAM214A HERC1 MAP2K1', 'FAM214A HERC1 MAP2K1 RPLP1', 'HERC1 MAP2K1 RPLP1 MYO9A', 'MAP2K1 RPLP1 MYO9A HBA1', 'RPLP1 MYO9A HBA1 RPS2', 'MYO9A HBA1 RPS2 WWOX', 'HBA1 RPS2 WWOX PIK3R5', 'RPS2 WWOX PIK3R5 NUFIP2', 'WWOX PIK3R5 NUFIP2 KAT7', 'PIK3R5 NUFIP2 KAT7 H3F3B', 'NUFIP2 KAT7 H3F3B TNRC6C', 'KAT7 H3F3B TNRC6C ACTG1', 'H3F3B TNRC6C ACTG1 ROCK1', 'TNRC6C ACTG1 ROCK1 NPC1', 'ACTG1 ROCK1 NPC1 RNF125', 'ROCK1 NPC1 RNF125 SMAD2', 'NPC1 RNF125 SMAD2 RPL17', 'RNF125 SMAD2 RPL17 AC027097.2', 'SMAD2 RPL17 AC027097.2 ZNF407', 'RPL17 AC027097.2 ZNF407 CALR', 'AC027097.2 ZNF407 CALR MAU2', 'ZNF407 CALR MAU2 URI1', 'CALR MAU2 URI1 LSM14A', 'MAU2 URI1 LSM14A ZFP36', 'URI1 LSM14A ZFP36 RPL13A', 'LSM14A ZFP36 RPL13A RPL28', 'ZFP36 RPL13A RPL28 PTPRA', 'RPL13A RPL28 PTPRA SLX4IP', 'RPL28 PTPRA SLX4IP KIZ', 'PTPRA SLX4IP KIZ APMAP', 'SLX4IP KIZ APMAP RBM39', 'KIZ APMAP RBM39 RALGAPB', 'APMAP RBM39 RALGAPB ZHX3', 'RBM39 RALGAPB ZHX3 ATP5F1E', 'RALGAPB ZHX3 ATP5F1E RUNX1', 'ZHX3 ATP5F1E RUNX1 TTC3', 'ATP5F1E RUNX1 TTC3 SFI1', 'RUNX1 TTC3 SFI1 TMSB4X', 'TTC3 SFI1 TMSB4X BRWD3', 'SFI1 TMSB4X BRWD3 CHM', 'TMSB4X BRWD3 CHM DIAPH2', 'BRWD3 CHM DIAPH2 RPL39', 'CHM DIAPH2 RPL39 FLNA', 'DIAPH2 RPL39 FLNA']\n"
     ]
    }
   ],
   "source": [
    "def chunk_sig(sig: str, chunk_size: int) -> list[str]:\n",
    "    chunks = []\n",
    "    items = sig1.split(\" \")\n",
    "    for i in range(len(items)):\n",
    "        if i + chunk_size > len(items):\n",
    "            chunks.append(\" \".join(items[i:]))\n",
    "            break\n",
    "        else:\n",
    "            chunks.append(\" \".join(items[i : i + chunk_size]))\n",
    "    return chunks\n",
    "\n",
    "\n",
    "chunks = chunk_sig(sig1, 4)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
