{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# test out cleaning up markdown files\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-01 19:37:21.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mfound 869 markdown files\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# read the files\n",
    "#\n",
    "from pathlib import Path \n",
    "from loguru import logger\n",
    "\n",
    "data_path = Path('data')\n",
    "md_files = list(data_path.glob(\"*.md\"))\n",
    "logger.info(\"found %d markdown files\" % len(md_files,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def markdown_to_text(markdown_str:str)->str:\n",
    "    html = markdown.markdown(markdown_str)\n",
    "    soup = BeautifulSoup(html, features='html.parser')\n",
    "    lines = soup.get_text().split(\"\\n\")\n",
    "    lines = [line.strip().lower() for line in lines if len(line) > 0]\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"demetra\\ncovid\\ntaking a big toll, especially if they can't work from home\\nmunaca\\nno acute crises\\nnothing critical this week\\nbut two tcp courses next week that will be hard to replace\\nmm is working on alternate plans\\nmay is the worst possible timing\\ncritical accreditation visits\\ncmarc\\nanimal services approved enough to keep working\\nmartha reached out because cecile has cold feet\\nmay 2,3 coming in over a weekend\\ngoing to meet with a lot of people\\ndirector of operations\\njarrod doing a great job\\ntwo other candidates\\npeople are engaged and hopeful that there can be real change\\nhr\\n- em needs to leave\\nwell\\nfinance\\nother than 10m..\\ncatherine wants $750k\\nhuge bill related to it systems\\nthis element of the budget needs to be rediscussed\\naccreditation needed\\nrationale for the rest?\\nco\\ndirector search underway: marie-eve\\nother positions\\nihpp\\nsace\\npatricia\\ncreate aqi --> both education and systems that support the faculty\\nspgh\\nabsolutely no movement on the campus planning side\\ncritical retirements\\nteresa is retiring in june\\nanna maria in august\\noffer them consultancies for the transition\\nto act as mentors\\nhelp with knowledge transfer\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = md_files[0]\n",
    "with open(input_file,mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()\n",
    "txt = markdown_to_text(data)\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "docs = text_splitter.create_documents([txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"demetra\\ncovid\\ntaking a big toll, especially if they can't work from home\\nmunaca\\nno acute crises\\nnothing critical this week\\nbut two tcp courses next week that will be hard to replace\\nmm is working on alternate plans\\nmay is the worst possible timing\"),\n",
       " Document(page_content='critical accreditation visits\\ncmarc\\nanimal services approved enough to keep working\\nmartha reached out because cecile has cold feet\\nmay 2,3 coming in over a weekend\\ngoing to meet with a lot of people\\ndirector of operations\\njarrod doing a great job'),\n",
       " Document(page_content='two other candidates\\npeople are engaged and hopeful that there can be real change\\nhr\\n- em needs to leave\\nwell\\nfinance\\nother than 10m..\\ncatherine wants $750k\\nhuge bill related to it systems\\nthis element of the budget needs to be rediscussed'),\n",
       " Document(page_content='accreditation needed\\nrationale for the rest?\\nco\\ndirector search underway: marie-eve\\nother positions\\nihpp\\nsace\\npatricia\\ncreate aqi --> both education and systems that support the faculty\\nspgh\\nabsolutely no movement on the campus planning side'),\n",
       " Document(page_content='critical retirements\\nteresa is retiring in june\\nanna maria in august\\noffer them consultancies for the transition\\nto act as mentors\\nhelp with knowledge transfer')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "txts = [txt.page_content for txt in docs]\n",
    "embeddings = embedding_model.embed_documents(txts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-01 20:36:40.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mprocessing 9 files\u001b[0m\n",
      "\u001b[32m2024-05-01 20:36:40.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mobtained 9 pages\u001b[0m\n",
      "\u001b[32m2024-05-01 20:36:40.743\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mPage 0: 5 chunks\u001b[0m\n",
      "\u001b[32m2024-05-01 20:36:40.744\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mPage 1: 2 chunks\u001b[0m\n",
      "\u001b[32m2024-05-01 20:36:40.745\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mPage 2: 20 chunks\u001b[0m\n",
      "\u001b[32m2024-05-01 20:36:40.745\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mPage 3: 0 chunks\u001b[0m\n",
      "\u001b[32m2024-05-01 20:36:40.746\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mPage 4: 3 chunks\u001b[0m\n",
      "\u001b[32m2024-05-01 20:36:40.747\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mPage 5: 6 chunks\u001b[0m\n",
      "\u001b[32m2024-05-01 20:36:40.748\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mPage 6: 1 chunks\u001b[0m\n",
      "\u001b[32m2024-05-01 20:36:40.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mPage 7: 1 chunks\u001b[0m\n",
      "\u001b[32m2024-05-01 20:36:40.750\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mPage 8: 5 chunks\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# try langchain's markdown splitter\n",
    "#\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "from datetime import datetime\n",
    "from langchain_text_splitters.markdown import MarkdownTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "@dataclass\n",
    "class MarkdownPage:\n",
    "    texts:list[str] = field(default_factory=list)\n",
    "    chunks:list[Document] = field(default_factory=list)\n",
    "    meta: dict[str,Any] = field(default_factory=dict)\n",
    "    embeddings: list[list[float]] = field(default_factory=list)\n",
    "    ids: list[str] = field(default_factory=list)\n",
    "\n",
    "    def __str__(self):\n",
    "        buffer = []\n",
    "        if self.chunks:\n",
    "            s = f\"File:{self.meta[\"filename\"]}\"\n",
    "            buffer.append(s)\n",
    "            for i in range(len(self.chunks)):\n",
    "                buffer.append(f\"   {self.chunks[i].page_content[0:10]}..{self.chunks[i].page_content[-10:]} [{self.embeddings[i][0]}..{self.embeddings[i][-1]}] {self.ids[i]}\")\n",
    "        elif self.texts:\n",
    "            s = f\"File:{self.meta[\"filename\"]}\"\n",
    "            buffer.append(s)\n",
    "            for i in range(len(self.texts)):\n",
    "                buffer.append(f\"    {self.texts[i][0:10]}...{self.texts[i][-10:]}\")\n",
    "        else:\n",
    "            buffer.append(\"Empty page!\")\n",
    "        return \"\\n\".join(buffer)\n",
    "    \n",
    "splitter = MarkdownTextSplitter()\n",
    "md_files = list(Path('data').glob(\"*.md\"))\n",
    "input_files = md_files[1:10]\n",
    "logger.debug(\"processing %d files\" % len(input_files))\n",
    "pages: list[MarkdownPage] = []\n",
    "for input in input_files:\n",
    "    page = MarkdownPage()\n",
    "    modified: datetime = datetime.fromtimestamp(input.stat().st_mtime)\n",
    "    page.meta = {\"filename\":input.as_posix(),\"created\":f\"{modified}\"}\n",
    "    with open(input) as f:\n",
    "        txt = f.read()\n",
    "        page.texts.append(txt.lower())\n",
    "    pages.append(page)\n",
    "logger.debug(\"obtained %d pages\" % len(pages))\n",
    "splitter = MarkdownTextSplitter(chunk_size=256, chunk_overlap=25)\n",
    "for i, page in enumerate(pages):\n",
    "    page.chunks = splitter.create_documents(page.texts)\n",
    "    logger.debug(f\"Page {i}: {len(page.chunks)} chunks\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File:data/arsenault-20220524-discipline.md\n",
      "   # discipli..l'étudiant [-0.0003534394492312683..-0.0135494694164122] data/arsenault-20220524-discipline.md(0)\n",
      "   désagréabl.. réligieux [-0.00593647298521481..-0.012724847262800624] data/arsenault-20220524-discipline.md(1)\n",
      "   ## je fais..amilariser [0.009180410078334486..-0.017850069804628554] data/arsenault-20220524-discipline.md(2)\n",
      "   j'ai reçu ..e taquines [-0.02339526939282548..0.004376598034155303] data/arsenault-20220524-discipline.md(3)\n",
      "   les vieux ..t présente [-0.014342402217993483..-0.0009903166807309937] data/arsenault-20220524-discipline.md(4)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "model = OpenAIEmbeddings()\n",
    "\n",
    "for page in pages:\n",
    "    chunks = [chunk.page_content for chunk in page.chunks]\n",
    "    page.embeddings = model.embed_documents(chunks)\n",
    "    # logger.debug(\"%d chunks -> %d embeddings\" % (len(chunks), len(page.embeddings)))\n",
    "    prefix = f\"{page.meta[\"filename\"]}\"\n",
    "    for i in range(len(chunks)):\n",
    "        page.ids.append(f\"{prefix}({i})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragsc-In6je0iX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
